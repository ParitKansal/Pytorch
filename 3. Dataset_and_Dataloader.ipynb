{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ParitKansal/Pytorch/blob/main/3.%20Dataset_and_Dataloader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TgAOwS2a3Keb"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_classification\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Create a synthetic classification dataset using sklearn\n",
        "X, y = make_classification(\n",
        "    n_samples=10,       # Number of samples\n",
        "    n_features=2,       # Number of features\n",
        "    n_informative=2,    # Number of informative features\n",
        "    n_redundant=0,      # Number of redundant features\n",
        "    n_classes=2,        # Number of classes\n",
        "    random_state=42     # For reproducibility\n",
        ")"
      ],
      "metadata": {
        "id": "aqEej4GC3UyT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBb4gaS_3cYe",
        "outputId": "25f6d9c2-a1e0-4204-be02-86f34219557f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10, 2), (10,))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the data to PyTorch tensors\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "hm8_V0OQ3hby"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "7nm0KeiA3lxj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, features, labels, transform=None):\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample, label = self.features[index], self.labels[index]\n",
        "        # Apply transformation to features if any\n",
        "        sample = sample*100\n",
        "        return sample, label"
      ],
      "metadata": {
        "id": "_WdH2NCq4zLD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset(X, y)"
      ],
      "metadata": {
        "id": "mbEXolf88_zV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=False)"
      ],
      "metadata": {
        "id": "0v4w5dki9QDu"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_features, batch_labels in dataloader:\n",
        "\n",
        "  print(batch_features)\n",
        "  print(batch_labels)\n",
        "  print(\"-\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AE9Ji0l9gVB",
        "outputId": "c83bed77-6de9-469f-969e-fd149d4bbc41"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 106.8339,  -97.0073],\n",
            "        [-114.0215,  -83.8792]])\n",
            "tensor([1., 0.])\n",
            "--------------------------------------------------\n",
            "tensor([[-289.5397,  197.6862],\n",
            "        [ -72.0634,  -96.0592]])\n",
            "tensor([0., 0.])\n",
            "--------------------------------------------------\n",
            "tensor([[-196.2874,  -99.2251],\n",
            "        [ -93.8205,  -54.3048]])\n",
            "tensor([0., 1.])\n",
            "--------------------------------------------------\n",
            "tensor([[ 172.7259, -118.5827],\n",
            "        [ 177.7366,  151.1576]])\n",
            "tensor([1., 1.])\n",
            "--------------------------------------------------\n",
            "tensor([[ 189.9693,   83.4445],\n",
            "        [ -58.7231, -197.1718]])\n",
            "tensor([1., 0.])\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label\n",
        "\n",
        "dataset = CustomImageDataset(\"fashion_mnist_images/labels/train_labels.csv\", \"fashion_mnist_images/train_images\")"
      ],
      "metadata": {
        "id": "UUeM7wNgjo4a"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "hyrAUwgKj0tl"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_features, batch_labels in dataloader:\n",
        "\n",
        "  print(batch_features.shape)\n",
        "  print(batch_labels.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yN6WIlfCkdEo",
        "outputId": "66cfe051-792a-4587-d03a-acdcb833b20a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from PIL import Image\n",
        "\n",
        "# Step 1: Load the FashionMNIST dataset\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "# Step 2: Define directories\n",
        "output_dir = \"fashion_mnist_images\"\n",
        "train_dir = os.path.join(output_dir, \"train_images\")\n",
        "test_dir = os.path.join(output_dir, \"test_images\")\n",
        "labels_dir = os.path.join(output_dir, \"labels\")  # Directory for CSV files\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "os.makedirs(labels_dir, exist_ok=True)\n",
        "\n",
        "# Step 3: Function to save images and create a CSV file\n",
        "def save_images_and_csv(dataset, image_directory, csv_directory, csv_filename):\n",
        "    \"\"\"\n",
        "    Save images from the dataset into the specified directory and create a CSV file\n",
        "    mapping filenames to their labels.\n",
        "\n",
        "    Args:\n",
        "        dataset: Dataset object containing images and labels.\n",
        "        image_directory: Directory to save the images.\n",
        "        csv_directory: Directory to save the CSV file.\n",
        "        csv_filename: Name of the CSV file.\n",
        "    \"\"\"\n",
        "    csv_path = os.path.join(csv_directory, csv_filename)\n",
        "    with open(csv_path, mode='w', newline='') as csv_file:\n",
        "        writer = csv.writer(csv_file)\n",
        "        writer.writerow([\"file_name\", \"label\"])  # Write header row\n",
        "\n",
        "        for index, (image, label) in enumerate(dataset):\n",
        "            # Convert tensor to PIL image\n",
        "            image = Image.fromarray((image.numpy().squeeze() * 255).astype('uint8'))\n",
        "            # Define file name\n",
        "            file_name = f\"{index}.png\"\n",
        "            # Save the image\n",
        "            image.save(os.path.join(image_directory, file_name))\n",
        "            # Write the file name and label to the CSV\n",
        "            writer.writerow([file_name, label])\n",
        "\n",
        "# Step 4: Save training data\n",
        "save_images_and_csv(training_data, train_dir, labels_dir, \"train_labels.csv\")\n",
        "\n",
        "# Step 5: Save testing data\n",
        "save_images_and_csv(test_data, test_dir, labels_dir, \"test_labels.csv\")\n",
        "\n",
        "print(f\"Images saved in {output_dir}/train and {output_dir}/test.\")\n",
        "print(f\"Labels saved in {output_dir}/labels.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulBWKtKwmahW",
        "outputId": "642f5e1e-ed73-4162-e6ea-75f6c07e43df"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images saved in fashion_mnist_images/train and fashion_mnist_images/test.\n",
            "Labels saved in fashion_mnist_images/labels.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iN2lJ_yp_vFK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}