{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ParitKansal/Pytorch/blob/main/3%2C%20Dataset_and_Dataloader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TgAOwS2a3Keb"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_classification\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Create a synthetic classification dataset using sklearn\n",
        "X, y = make_classification(\n",
        "    n_samples=10,       # Number of samples\n",
        "    n_features=2,       # Number of features\n",
        "    n_informative=2,    # Number of informative features\n",
        "    n_redundant=0,      # Number of redundant features\n",
        "    n_classes=2,        # Number of classes\n",
        "    random_state=42     # For reproducibility\n",
        ")"
      ],
      "metadata": {
        "id": "aqEej4GC3UyT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBb4gaS_3cYe",
        "outputId": "05941616-4235-4ff4-8d42-4f31822fd3ac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10, 2), (10,))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the data to PyTorch tensors\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "hm8_V0OQ3hby"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "7nm0KeiA3lxj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, features, labels, transform=None):\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample, label = self.features[index], self.labels[index]\n",
        "        # Apply transformation to features if any\n",
        "        sample = sample*100\n",
        "        return sample, label"
      ],
      "metadata": {
        "id": "_WdH2NCq4zLD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset(X, y)"
      ],
      "metadata": {
        "id": "mbEXolf88_zV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=False)"
      ],
      "metadata": {
        "id": "0v4w5dki9QDu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_features, batch_labels in dataloader:\n",
        "\n",
        "  print(batch_features)\n",
        "  print(batch_labels)\n",
        "  print(\"-\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AE9Ji0l9gVB",
        "outputId": "527be88f-8d37-46d3-ff42-19508a955baf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 106.8339,  -97.0073],\n",
            "        [-114.0215,  -83.8792]])\n",
            "tensor([1., 0.])\n",
            "--------------------------------------------------\n",
            "tensor([[-289.5397,  197.6862],\n",
            "        [ -72.0634,  -96.0592]])\n",
            "tensor([0., 0.])\n",
            "--------------------------------------------------\n",
            "tensor([[-196.2874,  -99.2251],\n",
            "        [ -93.8205,  -54.3048]])\n",
            "tensor([0., 1.])\n",
            "--------------------------------------------------\n",
            "tensor([[ 172.7259, -118.5827],\n",
            "        [ 177.7366,  151.1576]])\n",
            "tensor([1., 1.])\n",
            "--------------------------------------------------\n",
            "tensor([[ 189.9693,   83.4445],\n",
            "        [ -58.7231, -197.1718]])\n",
            "tensor([1., 0.])\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from PIL import Image\n",
        "\n",
        "# Step 1: Load the FashionMNIST dataset\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "# Step 2: Define directories\n",
        "output_dir = \"fashion_mnist_images\"\n",
        "train_dir = os.path.join(output_dir, \"train_images\")\n",
        "test_dir = os.path.join(output_dir, \"test_images\")\n",
        "labels_dir = os.path.join(output_dir, \"labels\")  # Directory for CSV files\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "os.makedirs(labels_dir, exist_ok=True)\n",
        "\n",
        "# Step 3: Function to save images and create a CSV file\n",
        "def save_images_and_csv(dataset, image_directory, csv_directory, csv_filename):\n",
        "    \"\"\"\n",
        "    Save images from the dataset into the specified directory and create a CSV file\n",
        "    mapping filenames to their labels.\n",
        "\n",
        "    Args:\n",
        "        dataset: Dataset object containing images and labels.\n",
        "        image_directory: Directory to save the images.\n",
        "        csv_directory: Directory to save the CSV file.\n",
        "        csv_filename: Name of the CSV file.\n",
        "    \"\"\"\n",
        "    csv_path = os.path.join(csv_directory, csv_filename)\n",
        "    with open(csv_path, mode='w', newline='') as csv_file:\n",
        "        writer = csv.writer(csv_file)\n",
        "        writer.writerow([\"file_name\", \"label\"])  # Write header row\n",
        "\n",
        "        for index, (image, label) in enumerate(dataset):\n",
        "            # Convert tensor to PIL image\n",
        "            image = Image.fromarray((image.numpy().squeeze() * 255).astype('uint8'))\n",
        "            # Define file name\n",
        "            file_name = f\"{index}.png\"\n",
        "            # Save the image\n",
        "            image.save(os.path.join(image_directory, file_name))\n",
        "            # Write the file name and label to the CSV\n",
        "            writer.writerow([file_name, label])\n",
        "\n",
        "# Step 4: Save training data\n",
        "save_images_and_csv(training_data, train_dir, labels_dir, \"train_labels.csv\")\n",
        "\n",
        "# Step 5: Save testing data\n",
        "save_images_and_csv(test_data, test_dir, labels_dir, \"test_labels.csv\")\n",
        "\n",
        "print(f\"Images saved in {output_dir}/train and {output_dir}/test.\")\n",
        "print(f\"Labels saved in {output_dir}/labels.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulBWKtKwmahW",
        "outputId": "d64e7d50-09a8-47c1-d68f-06ff3a0aed64"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 18.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 281kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 5.26MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 2.93MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Images saved in fashion_mnist_images/train and fashion_mnist_images/test.\n",
            "Labels saved in fashion_mnist_images/labels.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label\n",
        "\n",
        "dataset = CustomImageDataset(\"fashion_mnist_images/labels/train_labels.csv\", \"fashion_mnist_images/train_images\")"
      ],
      "metadata": {
        "id": "UUeM7wNgjo4a"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "hyrAUwgKj0tl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_features, batch_labels in dataloader:\n",
        "\n",
        "  print(batch_features.shape)\n",
        "  print(batch_labels.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yN6WIlfCkdEo",
        "outputId": "5b14fe68-0dbf-44b0-d5bd-c89590180e7b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from PIL import Image\n",
        "\n",
        "# Step 1: Load the FashionMNIST dataset\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "# Step 2: Define directories\n",
        "output_dir = \"fashion_mnist_images\"\n",
        "train_dir = os.path.join(output_dir, \"train_images\")\n",
        "test_dir = os.path.join(output_dir, \"test_images\")\n",
        "labels_dir = os.path.join(output_dir, \"labels\")  # Directory for CSV files\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "os.makedirs(labels_dir, exist_ok=True)\n",
        "\n",
        "# Step 3: Function to save images and create a CSV file\n",
        "def save_images_and_csv(dataset, base_image_directory, csv_directory, csv_filename):\n",
        "    \"\"\"\n",
        "    Save images from the dataset into labeled subdirectories and create a CSV file\n",
        "    mapping filenames to their labels.\n",
        "\n",
        "    Args:\n",
        "        dataset: Dataset object containing images and labels.\n",
        "        base_image_directory: Base directory to save the images.\n",
        "        csv_directory: Directory to save the CSV file.\n",
        "        csv_filename: Name of the CSV file.\n",
        "    \"\"\"\n",
        "    csv_path = os.path.join(csv_directory, csv_filename)\n",
        "    with open(csv_path, mode='w', newline='') as csv_file:\n",
        "        writer = csv.writer(csv_file)\n",
        "        writer.writerow([\"file_name\", \"label\"])  # Write header row\n",
        "\n",
        "        for index, (image, label) in enumerate(dataset):\n",
        "            # Convert tensor to PIL image\n",
        "            image = Image.fromarray((image.numpy().squeeze() * 255).astype('uint8'))\n",
        "\n",
        "            # Create subdirectory for the label if it doesn't exist\n",
        "            label_dir = os.path.join(base_image_directory, str(label))\n",
        "            os.makedirs(label_dir, exist_ok=True)\n",
        "\n",
        "            # Define file name\n",
        "            file_name = f\"{index}.png\"\n",
        "            file_path = os.path.join(label_dir, file_name)\n",
        "\n",
        "            # Save the image\n",
        "            image.save(file_path)\n",
        "\n",
        "            # Write the file name and label to the CSV\n",
        "            writer.writerow([os.path.relpath(file_path, base_image_directory), label])\n",
        "\n",
        "# Step 4: Save training data\n",
        "save_images_and_csv(training_data, train_dir, labels_dir, \"train_labels.csv\")\n",
        "\n",
        "# Step 5: Save testing data\n",
        "save_images_and_csv(test_data, test_dir, labels_dir, \"test_labels.csv\")\n",
        "\n",
        "print(f\"Images saved in labeled directories under {train_dir} and {test_dir}.\")\n",
        "print(f\"Labels saved in {labels_dir}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPiif7Y7DL74",
        "outputId": "164485e5-bd7b-4dcd-bbe2-31b0b428fc1f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images saved in labeled directories under fashion_mnist_images/train_images and fashion_mnist_images/test_images.\n",
            "Labels saved in fashion_mnist_images/labels.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.io import read_image\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform=None, target_transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data_dir (str): Directory containing image subdirectories organized by label.\n",
        "            transform (callable, optional): Optional transform to apply to images.\n",
        "            target_transform (callable, optional): Optional transform to apply to labels.\n",
        "        \"\"\"\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "\n",
        "        # Load images with labels\n",
        "        for label_dir in os.listdir(data_dir):\n",
        "            label_path = os.path.join(data_dir, label_dir)\n",
        "            if os.path.isdir(label_path):\n",
        "                label = int(label_dir)  # Convert label folder name to integer\n",
        "                for img_name in os.listdir(label_path):\n",
        "                    self.image_paths.append(os.path.join(label_path, img_name))\n",
        "                    self.labels.append(label)\n",
        "\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = read_image(img_path)\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Example usage\n",
        "data_dir = \"/content/fashion_mnist_images/train_images\"\n",
        "dataset = CustomImageDataset(data_dir)"
      ],
      "metadata": {
        "id": "MAi1abcYCYrE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "for batch_features, batch_labels in dataloader:\n",
        "  print(batch_features.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lD6vbOS7DYWk",
        "outputId": "6d53241b-f1cc-4684-cd6c-c7f041f99618"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 28, 28])\n"
          ]
        }
      ]
    }
  ]
}
